<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Image Pipeline | Eklavya 2023  </title>
    <meta name="author" content="Eklavya 2023  ">
    <meta name="description" content="Converting Raw image to meaningful image">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/projects/1_project/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Eklavya 2023 </span></a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">Home</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">blog</a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/leaderboard/">Leaderboard</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">Eklavya Projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/tasks/">Tasks</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Image Pipeline</h1>
            <p class="post-description">Converting Raw image to meaningful image</p>
          </header>

          <article>
            <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/intro.gif-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/intro.gif-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/intro.gif-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/intro.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

<!-- TABLE OF CONTENTS -->

<h1 id="table-of-contents">Table of Contents</h1>

<ul>
  <li>
<a href="#sketch-2-paint">Image Pipeline</a>
    <ul>
      <li><a href="#table-of-contents">Table of Contents</a></li>
    </ul>
  </li>
  <li>
<a href="#about-the-project">About The Project</a>
    <ul>
      <li><a href="#aim">Aim</a></li>
      <li><a href="#description">Description</a></li>
      <li><a href="#tech-stack">Tech Stack</a></li>
      <li><a href="#file-structure">File Structure</a></li>
    </ul>
  </li>
  <li>
<a href="#getting-started">Getting Started</a>
    <ul>
      <li><a href="#prerequisites">Prerequisites</a></li>
      <li><a href="#installation">Installation</a></li>
    </ul>
  </li>
  <li><a href="#usage">Usage</a></li>
  <li><a href="#theory-and-approach">Theory and Approach</a></li>
  <li><a href="#results-and-demo">Results and Demo</a></li>
  <li><a href="#future-works">Future Works</a></li>
  <li><a href="#contributors">Contributors</a></li>
  <li><a href="#acknowledgements-and-resources">Acknowledgements and Resources</a></li>
  <li>
<a href="#license">License</a>
<!-- About The Project -->
</li>
</ul>

<h1 id="about-the-project">About The Project</h1>

<!-- Aim -->

<h2 id="aim">Aim</h2>

<ul>
  <li>JPEG images are the ‘ready to view’ processed outputs from a camera.</li>
  <li>In computational photography, it can be useful to work directly with the raw sensor data from a digital camera.</li>
  <li>So-called RAW processing and RAW files must generally be processed before they can be displayed.</li>
  <li>In this project, we will implement our own RAW image reader</li>
</ul>

<h2 id="description">Description</h2>

<ul>
  <li>The image pipeline takes raw image from sensor and convert it to meaningful image. Several algorithms like debayering, Black Level correction, auto-white balance, denoising.. will be first implemented to construct a meaningful image.</li>
  <li>Then additional algorithms can be implemented on the constructed image to post-process it. Like Flipping, blending and overlaying images.</li>
  <li>All algorithms will be implemented on a static raw image captured from a sensor.</li>
  <li>The first part of this project is similar to what happens in an ISP (Image Signal Processor) in which all algorithms are designed based on hardware, but we will be designing those such that they are hardware independent.</li>
</ul>

<h2 id="tech-stack">Tech Stack</h2>

<p>This section contains the technologies we used for this project.</p>

<ul>
  <li>C++</li>
  <li>OpenCV</li>
  <li>Python</li>
</ul>

<h2 id="file-structure">File Structure</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>├── assets                   # Folder containing pngs
├── notes                    # Notes of Debayering and other algorithms
├── rawimages                # RAW Images used for testing
├── src                      # Source code files
    ├── CMakeLists.txt
    ├── auto_exposure.cpp
    ├── auto_white_balance.cpp
    ├── black_level_correction.cpp
    ├── color_space_conversion.cpp
    ├── conversion.cpp
    ├── create_image.cpp
    ├── dcraw.c
    ├── debayering.cpp
    ├── edges.cpp
    ├── filters.cpp
    ├── gamma.cpp
    ├── main.cpp
    ├── morphology.cpp
    ├── read_image.py
├── include                  # Header files
    ├── auto_exposure.h
    ├── auto_white_balance.h
    ├── black_level_correction.h
    ├── color_space_conversion.h
    ├── conversion.h
    ├── create_image.h
    ├── debayering.h
    ├── edges.h
    ├── filters.h
    ├── gamma.h
├── LICENSE                  # MIT license
├── README.md                # readme.md
</code></pre></div></div>

<h1 id="getting-started">Getting Started</h1>

<h2 id="prerequisites">Prerequisites</h2>

<p>To download and use this code, the minimum requirements are:</p>

<ul>
  <li><a href="https://opencv.org/releases/" rel="external nofollow noopener" target="_blank">OpenCV</a></li>
  <li>Windows 7 or later (64-bit), Ubuntu 20.04 or later</li>
  <li><a href="https://code.visualstudio.com/download" rel="external nofollow noopener" target="_blank">Microsoft VS Code</a></li>
</ul>

<h2 id="installation">Installation</h2>

<p>Clone the repo</p>

<p>` git clone https://github.com/HAWKEYE-HS/Image_Pipeline`</p>

<h2 id="usage">Usage</h2>

<p>Once the requirements are satisfied, you can easily download the project and use it on your machine.</p>

<ol>
  <li>First navigate to the folder Image_Pipeline</li>
  <li><code class="language-plaintext highlighter-rouge">mkdir build</code></li>
  <li><code class="language-plaintext highlighter-rouge">cd build</code></li>
  <li><code class="language-plaintext highlighter-rouge">cmake ../src</code></li>
  <li><code class="language-plaintext highlighter-rouge">make</code></li>
  <li><code class="language-plaintext highlighter-rouge">dcraw -4 -d -v -T &lt;raw_file_name&gt;</code></li>
  <li><code class="language-plaintext highlighter-rouge">../bin/working  &lt;gamma_value&gt; &lt;path_to_image_file (.tiff file)&gt;</code></li>
</ol>

<h2 id="theory-and-approach">Theory and Approach</h2>

<p>Refer <a href="/notes/THEORY.md">this</a> for more info</p>

<h3 id="debayering">Debayering</h3>

<ul>
  <li>Debayering, also known as demosaicing, is the process to convert a CFA image (m-by-n) to a true RGB color digital image (m-by-n-by-3).</li>
  <li>Refer <a href="/notes/DEBAYERING.md">this</a> for more info on debayering.</li>
</ul>

<h3 id="black-level-correction">Black Level Correction</h3>

<p>Black level leads to the whitening of image’s dark region and perceived loss of overall contrast
So the goal of this algorithm is to make Black to be Black</p>

<h3 id="white-balance">White Balance</h3>

<ul>
  <li>Any object can look like any color, depending on the light illuminating it. To reveal the color that we would see as humans, what we need is a reference point, something we know should be a certain color (or more accurately, a certain chromaticity). Then, we can rescale the R, G, B values of the pixel until it is that color.</li>
  <li>As it is usually possible to identify objects that should be white, we will find a pixel we know should be white (or gray), which we know should have RGB values all equal, and then we find the scaling factors necessary to force each channel’s value to be equal.</li>
  <li>As such, this rescaling process is called white balancing.</li>
</ul>

<h3 id="auto-exposure">Auto Exposure</h3>

<ul>
  <li>If too much light strikes the image sensor, the image will be overexposed, washed out, and faded.</li>
  <li>If too little light reaches the camera sensor produces an underexposed image, dark and lacking in details, especially in shadow areas.</li>
  <li>Image channel having normalized values in the range 0-1 is run through a loop where each pixel value is compared to the mean intensity value of the image and correction is applied accordingly</li>
</ul>

<h3 id="auto-adjustment">Auto Adjustment</h3>

<ul>
  <li>Brightness and contrast is linear operator with parameter <code class="language-plaintext highlighter-rouge">alpha</code> and <code class="language-plaintext highlighter-rouge">beta</code>
</li>
</ul>

<p><code class="language-plaintext highlighter-rouge">O(x,y) = alpha * I(x,y) + beta</code></p>

<ul>
  <li>
    <p>Looking at histogram, alpha operates as color range amplifier, beta operates as range shift.</p>
  </li>
  <li>
    <p>Automatic brightness and contrast optimization calculates alpha and beta so that the output range is 0..255.</p>
  </li>
</ul>

<p><code class="language-plaintext highlighter-rouge">input range = max(I) - min(I)
wanted output range = 255;
alpha = output range / input range =  255 / ( max(I) - min(I) )</code></p>

<ul>
  <li>You can calculate beta so that min(O) = 0;</li>
</ul>

<p><code class="language-plaintext highlighter-rouge">min(O) = alpha * min(I) + beta
beta = -min(I) * alpha</code></p>

<h3 id="gamma-correction">Gamma Correction</h3>

<ul>
  <li>Gamma correction is also known as the Power Law Transform.</li>
  <li>
    <p>First, our image pixel intensities must be scaled from the range [0, 255] to [0, 1.0]. From there, we obtain our output gamma corrected image by applying the following equation:</p>

    <p>O = I <sup>(1 / G)</sup></p>

    <p>Where <b>I</b> is our input image and <b>G</b> is our gamma value. The output image <b>O</b> is then scaled back to the range [0, 255].</p>
  </li>
</ul>

<p><img src="/assets/preprocessing.png" alt="Preprocessing"></p>

<h3 id="rgb--grayscale">RGB –&gt; Grayscale</h3>

<ul>
  <li>
    <p>The best method is the luminosity method that successfully solves the problems of previous methods.</p>
  </li>
  <li>Based on the aforementioned observations, we should take a weighted average of the components. The contribution of blue to the final value should decrease, and the contribution of green should increase.</li>
  <li>After some experiments and more in-depth analysis, researchers have concluded in the equation below:</li>
</ul>

<p><code class="language-plaintext highlighter-rouge">grayscale = (0.3 * R + 0.59 * G + 0.11 * B)/3</code></p>

<h3 id="grayscale--binary">Grayscale –&gt; Binary</h3>

<ul>
  <li>Binary images are images whose pixels have only two possible intensity values. They are normally displayed as black and white.</li>
  <li>
    <p>Numerically, the two values are often 0 for black, and either 1 or 255 for white.</p>
  </li>
  <li>Binary images are often produced by thresholding a grayscale or color image, in order to separate an object in the image from the background.</li>
</ul>

<h3 id="rgb--hsv">RGB –&gt; HSV</h3>

<ul>
  <li>HSV – (hue, saturation, value), also known as HSB (hue, saturation, brightness), is often used by artists because it is often more natural to think about a color in terms of hue and saturation than in terms of additive or subtractive color components.</li>
  <li>HSV is a transformation of an RGB colorspace, and its components and colorimetry are relative to the RGB colorspace from which it was derived.</li>
</ul>

<h3 id="sobel-edge-detection">Sobel Edge Detection</h3>

<ul>
  <li>An edge in an image is a significant local change in the image intensity. As the name suggests, edge detection is the process of detecting the edges in an image.</li>
  <li>The Sobel operator performs a 2-D spatial gradient measurement on an image and so emphasizes regions of high spatial frequency that correspond to edges. Typically it is used to find the approximate absolute gradient magnitude at each point in an input grayscale image.</li>
  <li>In theory at least, the operator consists of a pair of 3×3 convolution kernels. One kernel is simply the transpose of other.</li>
  <li>These kernels are designed to respond maximally to edges running vertically and horizontally relative to the pixel grid, one kernel for each of the two perpendicular orientations.</li>
</ul>

<h3 id="morphological-operations">Morphological Operations</h3>

<h4 id="erosion">Erosion</h4>

<ul>
  <li>The basic idea of erosion is just like soil erosion only, it erodes away the boundaries of foreground object (Always try to keep foreground in white).</li>
  <li>The kernel slides through the image (as in 2D convolution).</li>
  <li>A pixel in the original image (either 1 or 0) will be considered 1 only if all the pixels under the kernel is 1, otherwise it is eroded (made to zero).</li>
</ul>

<h4 id="dilation">Dilation</h4>

<ul>
  <li>Opposite of erosion.</li>
  <li>Here, a pixel element is ‘1’ if at least one pixel under the kernel is ‘1’. So it increases the white region in the image or size of foreground object increases.</li>
</ul>

<h4 id="closing">Closing</h4>

<ul>
  <li>
<b>Reverse of Opening</b>, Dilation followed by Erosion.</li>
  <li>It is useful in closing small holes inside the foreground objects, or small black points on the object.</li>
</ul>

<h4 id="opening">Opening</h4>

<p>Opening is just another name of <b>erosion</b> followed by <b>dilation</b>. It is useful in removing noise, as we explained above.</p>

<h4 id="gradient">Gradient</h4>

<ul>
  <li>
    <p>It is the <b>difference</b> between <b>dilation</b> and <b>erosion</b> of an image.</p>
  </li>
  <li>
    <p>The result will look like the <b>outline</b> of the object.</p>
  </li>
</ul>

<h3 id="blurring">Blurring</h3>

<ul>
  <li>Image blurring is achieved by convolving the image with a low-pass filter kernel.</li>
  <li>It is useful for removing noise.</li>
  <li>It actually removes high frequency content (eg: noise, edges) from the image.</li>
  <li>So edges are blurred a little bit in this operation (there are also blurring techniques which don’t blur the edges).</li>
</ul>

<h4 id="1-averaging">1. Averaging</h4>

<ul>
  <li>This is done by convolving an image with a normalized box filter.</li>
  <li>It simply takes the average of all the pixels under the kernel area and replaces the central element.</li>
</ul>

<h4 id="2-gaussian-blur">2. Gaussian Blur</h4>

<ul>
  <li>In Gaussian Blur operation, the image is convolved with a Gaussian filter instead of the box filter.</li>
  <li>The Gaussian filter is a low-pass filter that removes the high-frequency components.</li>
</ul>

<h4 id="3-median-blur">3. Median Blur</h4>

<ul>
  <li>Here, the function takes the median of all the pixels under the kernel area and the central element is replaced with this median value.</li>
  <li>This is highly effective against salt-and-pepper noise in an image.</li>
</ul>

<h3 id="rotation">Rotation</h3>

<p><img src="assets/Rotation.png" alt="Rotation"></p>

<h2 id="results-and-demo">Results and Demo</h2>

<h3 id="preprocessing-results">Preprocessing Results</h3>

<table>
  <thead>
    <tr>
      <th style="text-align: center">RAW Image</th>
      <th style="text-align: center">Preprocessed Image</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><image src="assets/image3o.png" alt="Image1" width="350" height="200"></image></td>
      <td style="text-align: center"><image src="assets/image3.png" alt="PreImage" width="350" height="200"></image></td>
    </tr>
    <tr>
      <td style="text-align: center"><image src="assets/imageoutput2.png" alt="Image1" width="350" height="200"></image></td>
      <td style="text-align: center"><image src="assets/imageoutput1.png" alt="PreImage" width="350" height="200"></image></td>
    </tr>
    <tr>
      <td style="text-align: center"><image src="assets/image2o.png" alt="Image1" width="350" height="200"></image></td>
      <td style="text-align: center"><image src="assets/image2.png" alt="PreImage" width="350" height="200"></image></td>
    </tr>
    <tr>
      <td style="text-align: center"><image src="assets/image4.png" alt="Image1" width="350" height="200"></image></td>
      <td style="text-align: center"><image src="assets/image4o.png" alt="PreImage" width="350" height="200"></image></td>
    </tr>
    <tr>
      <td style="text-align: center"><image src="assets/flash.png" alt="Image1" width="350" height="200"></image></td>
      <td style="text-align: center"><image src="assets/flasho.png" alt="PreImage" width="350" height="200"></image></td>
    </tr>
  </tbody>
</table>

<hr>

<h3 id="post-processing">Post-Processing</h3>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Grayscale Conversion</th>
      <th style="text-align: center">Binary conversion</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><image src="assets/gray.png" alt="gray" width="350"></image></td>
      <td style="text-align: center"><image src="assets/binary.png" alt="grayscale" width="350"></image></td>
    </tr>
  </tbody>
</table>

<table>
  <thead>
    <tr>
      <th style="text-align: center">HSV Conversion</th>
      <th style="text-align: center">Sobel Edge Detection</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><image src="assets/hsv.png" alt="HSV" width="350"></image></td>
      <td style="text-align: center"><image src="assets/edges.png" alt="Edges" width="350"></image></td>
    </tr>
  </tbody>
</table>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Erosion</th>
      <th style="text-align: center">Dilation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><image src="assets/erode.png" alt="Erode" width="350"></image></td>
      <td style="text-align: center"><image src="assets/dilate.png" alt="Dilate" width="350"></image></td>
    </tr>
  </tbody>
</table>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Opening</th>
      <th style="text-align: center">Closing</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><image src="assets/opening.png" alt="Opening" width="350"></image></td>
      <td style="text-align: center"><image src="assets/closing.png" alt="Closing" width="350"></image></td>
    </tr>
  </tbody>
</table>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Gradient</th>
      <th style="text-align: center">Mean Filter</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><image src="assets/gradient.png" alt="Gradient" width="350"></image></td>
      <td style="text-align: center"><image src="assets/meanblur.png" alt="MeanBlur" width="350"></image></td>
    </tr>
  </tbody>
</table>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Gaussian Filter</th>
      <th style="text-align: center">Median Filter</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><image src="assets/gaussianblur.png" alt="GaussianBlur" width="350"></image></td>
      <td style="text-align: center"><image src="assets/median.png" alt="Median" width="350"></image></td>
    </tr>
  </tbody>
</table>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Original Image</th>
      <th style="text-align: center">Rotated Image(120<sup>o</sup>)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><image src="assets/median.png" alt="GaussianBlur" width="350"></image></td>
      <td style="text-align: center"><image src="assets/Rotated.png" alt="Median" width="350"></image></td>
    </tr>
  </tbody>
</table>

<h2 id="future-works">Future Works</h2>

<p>We enjoyed working on this project, got to know more about image representation. We will try to</p>

<ol>
  <li>Implement the library functions of OpenCV</li>
  <li>Extend the functionality to dynamic images.</li>
</ol>

<h2 id="contributors">Contributors</h2>

<ul>
  <li><a href="https://github.com/HAWKEYE-HS" rel="external nofollow noopener" target="_blank">Om Doiphode</a></li>
  <li><a href="https://github.com/KedarDhamankar" rel="external nofollow noopener" target="_blank">Kedar Dhamankar</a></li>
</ul>

<h2 id="acknowledgements-and-resources">Acknowledgements and Resources</h2>

<ul>
  <li>
    <p><a href="https://sravjti.in/" rel="external nofollow noopener" target="_blank">SRA VJTI</a> Eklavya Project 2022</p>
  </li>
  <li>
    <p>Referred <a href="https://www.google.com/url?sa=t&amp;source=web&amp;rct=j&amp;url=https://www.ipol.im/pub/art/2011/g_mhcd/article.pdf&amp;ved=2ahUKEwiA_s3fzbb6AhUS8jgGHceSBo8QFnoECAsQAQ&amp;usg=AOvVaw0Z6FMrGqqslKOP7gmv9Y38" rel="external nofollow noopener" target="_blank">this</a> for Demosaicing algorithm.</p>
  </li>
  <li>
    <p>Referred <a href="https://www.google.com/url?sa=t&amp;source=web&amp;rct=j&amp;url=http://dev.ipol.im/~nmonzon/Normalization.pdf&amp;ved=2ahUKEwjK_q2F0bb6AhWUzjgGHUwGAIYQFnoECBcQAQ&amp;usg=AOvVaw0Plz9s7KzA0SiCftLdy0oC" rel="external nofollow noopener" target="_blank">this</a> for Normalization of image</p>
  </li>
  <li>Referred <a href="https://www.codeproject.com/Articles/653355/Color-Constancy-Gray-World-Algorithm" rel="external nofollow noopener" target="_blank">this</a> for White Balancing Algorithm</li>
  <li>
    <p>Referred <a href="https://link.springer.com/article/10.1007/s11042-019-08318-1" rel="external nofollow noopener" target="_blank">this</a> for Auto Exposure Algorithm</p>
  </li>
  <li>
    <p>Referred <a href="https://www.cambridgeincolour.com/tutorials/gamma-correction.htm" rel="external nofollow noopener" target="_blank">this</a> for gamma correction</p>
  </li>
  <li>
    <p>Referred <a href="https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html" rel="external nofollow noopener" target="_blank">this</a> for morphological operations.</p>
  </li>
  <li>
    <p>Referred <a href="https://docs.opencv.org/4.x/d4/d13/tutorial_py_filtering.html" rel="external nofollow noopener" target="_blank">this</a> for Blurring algorithms.</p>
  </li>
  <li>
    <p>Referred <a href="https://medium.com/@haidarlina4/sobel-vs-canny-edge-detection-techniques-step-by-step-implementation-11ae6103a56a" rel="external nofollow noopener" target="_blank">this</a> for Sobel Edge Detection.</p>
  </li>
  <li>Special Thanks to our awesome mentors <a href="https://github.com/KunalA18" rel="external nofollow noopener" target="_blank">Kunal Agarwal</a> and <a href="https://github.com/Ris-Bali" rel="external nofollow noopener" target="_blank">Rishabh Bali</a> who always helped us during our project journey</li>
</ul>

<h2 id="license">License</h2>

<p>The <a href="/LICENSE">License</a> for this project</p>

          </article>

        </div>

      
    </div>

    <!-- Footer -->    <!-- 
    <footer class="fixed-bottom">
      <div class="container mt-0">
        &copy; Copyright 2023 Eklavya 2023  . Powered by <a href="https://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank">Unsplash</a>.

      </div>
    </footer> -->

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
